{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8870083,"sourceType":"datasetVersion","datasetId":5338273},{"sourceId":11663757,"sourceType":"datasetVersion","datasetId":7319979},{"sourceId":81881,"sourceType":"modelInstanceVersion","modelInstanceId":68809,"modelId":91102}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setting up","metadata":{}},{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U accelerate\n%pip install -U peft\n%pip install -U trl\n%pip install hf_xek","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T20:10:26.256061Z","iopub.execute_input":"2025-05-04T20:10:26.256365Z","iopub.status.idle":"2025-05-04T20:11:33.961750Z","shell.execute_reply.started":"2025-05-04T20:10:26.256322Z","shell.execute_reply":"2025-05-04T20:11:33.960497Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import wandb\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tuning for velsera', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:11:43.633168Z","iopub.execute_input":"2025-05-04T20:11:43.633792Z","iopub.status.idle":"2025-05-04T20:12:03.665844Z","shell.execute_reply.started":"2025-05-04T20:11:43.633760Z","shell.execute_reply":"2025-05-04T20:12:03.664753Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohitlakshya\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.19.10 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250504_201146-kmbmd8aa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera/runs/kmbmd8aa' target=\"_blank\">old-transport-8</a></strong> to <a href='https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera' target=\"_blank\">https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera/runs/kmbmd8aa' target=\"_blank\">https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera/runs/kmbmd8aa</a>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport bitsandbytes as bnb\nimport torch\nimport torch.nn as nn\nimport transformers\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftConfig\nfrom trl import SFTTrainer, SFTConfig\nfrom trl import setup_chat_format\nfrom transformers import (AutoModelForCausalLM, \n                          AutoTokenizer, \n                          BitsAndBytesConfig,\n                          pipeline, \n                          logging)\nfrom sklearn.metrics import (accuracy_score, \n                             classification_report, \n                             confusion_matrix)\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:12:09.145373Z","iopub.execute_input":"2025-05-04T20:12:09.145724Z","iopub.status.idle":"2025-05-04T20:12:27.708819Z","shell.execute_reply.started":"2025-05-04T20:12:09.145699Z","shell.execute_reply":"2025-05-04T20:12:27.707872Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-05-04 20:12:17.433224: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-05-04 20:12:17.433414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-05-04 20:12:17.570114: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Loading Dataset\n\n- Originally the data is provided in text files.\n- Those text files have three field, id, title and abstract\n- Loading 1000 files on kaggle was cumbersome, so I combined those files into a dataframe and uploaded a single file","metadata":{}},{"cell_type":"code","source":"cancer_df = pd.read_csv(\"/kaggle/input/cancer-non-cancer/cancer.csv\")\nnon_cancer_df = pd.read_csv(\"/kaggle/input/cancer-non-cancer/non_cancer.csv\")\ndf = pd.concat([cancer_df, non_cancer_df])\ndf[\"label\"] = [\"yes\" if y == \"cancer\" else \"no\" for y in df[\"y\"]]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:15:59.485258Z","iopub.execute_input":"2025-05-04T20:15:59.486188Z","iopub.status.idle":"2025-05-04T20:15:59.525029Z","shell.execute_reply.started":"2025-05-04T20:15:59.486154Z","shell.execute_reply":"2025-05-04T20:15:59.524184Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         id                                              title  \\\n0  31055803  [Analysis of age-specific cytogenetic changes ...   \n1  31164412  T-Cell Deletion of MyD88 Connects IL17 and Ika...   \n2  31094905  MYCN Amplified Relapse Following Resolution of...   \n3  31498304  In Vivo Inhibition of MicroRNA to Decrease Tum...   \n4  30897768  Breast Cancer and miR-SNPs: The Importance of ...   \n\n                                            abstract       y label  \n0  OBJECTIVE: To characterize cytogenetic changes...  cancer   yes  \n1  Cancer development requires a favorable tissue...  cancer   yes  \n2  Congenital neuroblastoma with placental involv...  cancer   yes  \n3  MicroRNAs (miRNAs) are important regulators of...  cancer   yes  \n4  Recent studies in cancer diagnostics have iden...  cancer   yes  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>y</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31055803</td>\n      <td>[Analysis of age-specific cytogenetic changes ...</td>\n      <td>OBJECTIVE: To characterize cytogenetic changes...</td>\n      <td>cancer</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31164412</td>\n      <td>T-Cell Deletion of MyD88 Connects IL17 and Ika...</td>\n      <td>Cancer development requires a favorable tissue...</td>\n      <td>cancer</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31094905</td>\n      <td>MYCN Amplified Relapse Following Resolution of...</td>\n      <td>Congenital neuroblastoma with placental involv...</td>\n      <td>cancer</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31498304</td>\n      <td>In Vivo Inhibition of MicroRNA to Decrease Tum...</td>\n      <td>MicroRNAs (miRNAs) are important regulators of...</td>\n      <td>cancer</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30897768</td>\n      <td>Breast Cancer and miR-SNPs: The Importance of ...</td>\n      <td>Recent studies in cancer diagnostics have iden...</td>\n      <td>cancer</td>\n      <td>yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df.label.value_counts() # equal split between cancer and non-cancer files","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T20:17:52.855982Z","iopub.execute_input":"2025-05-04T20:17:52.856330Z","iopub.status.idle":"2025-05-04T20:17:52.866348Z","shell.execute_reply.started":"2025-05-04T20:17:52.856306Z","shell.execute_reply":"2025-05-04T20:17:52.865396Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"label\nyes    500\nno     500\nName: count, dtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Prepare dataset for training and evaluation","metadata":{}},{"cell_type":"code","source":"df = df.sample(frac=1, random_state=85).reset_index(drop=True)\n\n# Split the DataFrame\nX = df.drop(columns=\"label\", axis=1)\ny = df[\"label\"]\n\nx_train, x_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\nx_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n\n# Define the prompt generation functions\ndef generate_prompt(**data_point):\n    return f\"\"\"Given the title and abstract of a research paper \nTitle: {data_point[\"title\"]}\nAbstract: {data_point[\"abstract\"]}\n\nIs the paper related with cancer? Answer with \"yes\" or \"no\" only.\nAnswer: {data_point[\"label\"]}\"\"\".strip()\n\ndef generate_test_prompt(**data_point):\n    return f\"\"\"Given the title and abstract of a research paper\nTitle: {data_point[\"title\"]}\nAbstract: {data_point[\"abstract\"]}\n\nIs the paper related with cancer? Answer with \"yes\" or \"no\" only.\nAnswer:\"\"\".strip()\n\nx_train[\"text\"] = [generate_prompt(title=t, abstract=a, label=y) for t, a, y in zip(x_train[\"title\"], x_train[\"abstract\"], y_train)]\nx_val[\"text\"] = [generate_test_prompt(title=t, abstract=a) for t, a in zip(x_val[\"title\"], x_val[\"abstract\"])]","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:19:08.206759Z","iopub.execute_input":"2025-05-04T20:19:08.207602Z","iopub.status.idle":"2025-05-04T20:19:08.230236Z","shell.execute_reply.started":"2025-05-04T20:19:08.207573Z","shell.execute_reply":"2025-05-04T20:19:08.229622Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Convert to datasets\ntrain_data = Dataset.from_pandas(x_train[[\"text\"]])\neval_data = Dataset.from_pandas(x_val[[\"text\"]])","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:19:14.040750Z","iopub.execute_input":"2025-05-04T20:19:14.041526Z","iopub.status.idle":"2025-05-04T20:19:14.069171Z","shell.execute_reply.started":"2025-05-04T20:19:14.041498Z","shell.execute_reply":"2025-05-04T20:19:14.068300Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_data['text'][3]","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:19:21.892483Z","iopub.execute_input":"2025-05-04T20:19:21.893283Z","iopub.status.idle":"2025-05-04T20:19:21.903688Z","shell.execute_reply.started":"2025-05-04T20:19:21.893255Z","shell.execute_reply":"2025-05-04T20:19:21.902607Z"},"trusted":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'Given the title and abstract of a research paper \\nTitle: Genetics meets pathology - an increasingly important relationship.\\nAbstract: The analytical power of modern methods for DNA analysis has outstripped our capability to interpret and understand the data generated. To make good use of this genomic data in a biomedical setting (whether for research or diagnosis), it is vital that we understand the mechanisms through which mutations affect biochemical pathways and physiological systems. This lies at the centre of what genetics is all about, and it is the reason why genetics and genomics should go hand in hand whenever possible. In this Annual Review Issue of The Journal of Pathology, we have assembled a collection of 16 expert reviews covering a wide range of topics. Through these, we illustrate the power of genetic analysis to improve our understanding of normal physiology and disease pathology, and thereby to think in rational ways about clinical management. Copyright   2016 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.\\n\\nIs the paper related with cancer? Answer with \"yes\" or \"no\" only.\\nAnswer: no'"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Loading the model and tokenizer","metadata":{}},{"cell_type":"markdown","source":"- We are using `unsloths` quantized models.\n- These models are small in size","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nfrom huggingface_hub.hf_api import HfFolder\n\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HUGGING_FACE_TOKEN\")\nHfFolder.save_token(secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T20:21:11.447814Z","iopub.execute_input":"2025-05-04T20:21:11.448192Z","iopub.status.idle":"2025-05-04T20:21:11.525096Z","shell.execute_reply.started":"2025-05-04T20:21:11.448167Z","shell.execute_reply":"2025-05-04T20:21:11.524201Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"base_model_name = \"unsloth/Llama-3.2-1B-bnb-4bit\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name,\n    device_map=\"auto\",\n    torch_dtype=\"float16\",\n    # quantization_config=bnb_config, \n).to(device)\n\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\ntokenizer = AutoTokenizer.from_pretrained(base_model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\n# Ignore the javascript error, this is because it is not able to show the loading bar","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:21:16.497118Z","iopub.execute_input":"2025-05-04T20:21:16.497872Z","iopub.status.idle":"2025-05-04T20:21:33.939134Z","shell.execute_reply.started":"2025-05-04T20:21:16.497846Z","shell.execute_reply":"2025-05-04T20:21:33.936366Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.51k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e899a2184fa7497facd04c134a4ae271"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ad65feae1f14f89a85e087972ec61e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a93b67913b0448e4854c974c319fb3c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb7324e53107443bbba92bee04664235"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f363688065974ad5a047f30406ffb5bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6df8b255ae546238fcd9227702c05e5"}},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Model evalution before fine-tuning","metadata":{}},{"cell_type":"code","source":"# def predict(test, model, tokenizer):\n#     y_pred = []\n#     categories = [\"yes\", \"no\"]\n    \n#     for i in tqdm(range(len(test))):\n#         prompt = test.iloc[i][\"text\"]\n#         pipe = pipeline(task=\"text-generation\", \n#                         model=model, \n#                         tokenizer=tokenizer, \n#                         # return_tensors=True,\n#                         max_new_tokens=2,\n#                         # num_return_sequences=4,\n#                         temperature=0.1, )\n        \n#         result = pipe(prompt) #, output_scores= True) #, \"output_logits\": True, \"return_dict_in_generate\": True})\n#         results.append(result)\n#         print(result)\n#         answer = result[0]['generated_text'].split(\"Answer:\")[-1].strip()\n        \n#         # Determine the predicted category\n#         for category in categories:\n#             if category.lower() in answer.lower():\n#                 y_pred.append(category)\n#                 break\n#         else:\n#             y_pred.append(\"none\")\n        \n#     return y_pred","metadata":{"execution":{"iopub.status.busy":"2025-05-04T12:10:22.168657Z","iopub.execute_input":"2025-05-04T12:10:22.169339Z","iopub.status.idle":"2025-05-04T12:10:22.174860Z","shell.execute_reply.started":"2025-05-04T12:10:22.169313Z","shell.execute_reply":"2025-05-04T12:10:22.173732Z"},"trusted":true},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def predict(test, model, tokenizer):\n    predictions = []\n    categories = [\"yes\", \"no\"]\n    \n    for i in tqdm(range(len(test))):\n        prompt = test.iloc[i][\"text\"]\n        \n        # Tokenize input\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n        input_ids = inputs[\"input_ids\"]\n        \n        # Generate output directly with the model\n        generated_outputs = model.generate(\n            input_ids,\n            do_sample=True,\n            max_new_tokens=2,\n            temperature=0.1,\n            num_return_sequences=1,\n            output_scores=True,\n            return_dict_in_generate=True\n        )\n        \n        gen_sequences = generated_outputs.sequences[:, input_ids.shape[-1]:]\n        \n        # Convert logits to probabilities\n        probs = torch.stack(generated_outputs.scores, dim=1).softmax(-1)\n        \n        # Collect probability of the generated tokens\n        gen_probs = torch.gather(probs, 2, gen_sequences[:, :, None]).squeeze(-1)\n        \n        # Calculate overall probability of the sequence (product of token probabilities)\n        sequence_prob = gen_probs.prod(-1).item()\n        \n        # Decode the generated tokens\n        generated_text = tokenizer.decode(gen_sequences[0], skip_special_tokens=True)\n        \n        # Determine the predicted category\n        predicted_label = \"none\"\n        for category in categories:\n            if category.lower() in generated_text.lower():\n                predicted_label = category\n                break\n        \n        # Create prediction dictionary\n        prediction = {\n            \"label\": predicted_label,\n            \"probability\": float(sequence_prob),\n            \"input_text\": prompt\n        }\n        \n        predictions.append(prediction)\n\n    x_test = test.copy()\n    x_test[\"predicted_label\"] = [x[\"label\"] for x in predictions]\n    x_test[\"predicted_probability\"] = [x[\"probability\"] for x in predictions]\n    \n    return x_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T20:24:59.504192Z","iopub.execute_input":"2025-05-04T20:24:59.504536Z","iopub.status.idle":"2025-05-04T20:24:59.514361Z","shell.execute_reply.started":"2025-05-04T20:24:59.504511Z","shell.execute_reply":"2025-05-04T20:24:59.513410Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"y_val_pred_df = predict(x_val, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:25:13.088729Z","iopub.execute_input":"2025-05-04T20:25:13.089417Z","iopub.status.idle":"2025-05-04T20:26:00.835978Z","shell.execute_reply.started":"2025-05-04T20:25:13.089381Z","shell.execute_reply":"2025-05-04T20:26:00.834822Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 200/200 [00:47<00:00,  4.19it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"y_val_pred_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T20:26:09.723312Z","iopub.execute_input":"2025-05-04T20:26:09.723979Z","iopub.status.idle":"2025-05-04T20:26:09.737606Z","shell.execute_reply.started":"2025-05-04T20:26:09.723943Z","shell.execute_reply":"2025-05-04T20:26:09.736768Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"           id                                              title  \\\n526  31266596  Renal cell carcinomas with a mesenchymal strom...   \n557  31212132  Identification of a novel orally bioavailable ...   \n290  31182949  Lack of Response to Vemurafenib in Melanoma Ca...   \n141  26432562  A Case of Recurrent Ischemic Stroke Involving ...   \n239  30937513  [Bronchoalveolar lavage in hairy cell leukemia...   \n\n                                              abstract           y  \\\n526  A subset of renal cell neoplasms contains a me...      cancer   \n557  Extracellular regulated kinase 5 (ERK5) signal...      cancer   \n290  Vemurafenib has been developed to target commo...      cancer   \n141  CASE REPORT: A 58-year-old man presenting with...  non_cancer   \n239  We report a 78-year-old male patient suffering...      cancer   \n\n                                                  text predicted_label  \\\n526  Given the title and abstract of a research pap...             yes   \n557  Given the title and abstract of a research pap...             yes   \n290  Given the title and abstract of a research pap...             yes   \n141  Given the title and abstract of a research pap...             yes   \n239  Given the title and abstract of a research pap...             yes   \n\n     predicted_probability  \n526               0.884039  \n557               1.000000  \n290               0.196826  \n141               0.803174  \n239               0.735218  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>y</th>\n      <th>text</th>\n      <th>predicted_label</th>\n      <th>predicted_probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>526</th>\n      <td>31266596</td>\n      <td>Renal cell carcinomas with a mesenchymal strom...</td>\n      <td>A subset of renal cell neoplasms contains a me...</td>\n      <td>cancer</td>\n      <td>Given the title and abstract of a research pap...</td>\n      <td>yes</td>\n      <td>0.884039</td>\n    </tr>\n    <tr>\n      <th>557</th>\n      <td>31212132</td>\n      <td>Identification of a novel orally bioavailable ...</td>\n      <td>Extracellular regulated kinase 5 (ERK5) signal...</td>\n      <td>cancer</td>\n      <td>Given the title and abstract of a research pap...</td>\n      <td>yes</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>31182949</td>\n      <td>Lack of Response to Vemurafenib in Melanoma Ca...</td>\n      <td>Vemurafenib has been developed to target commo...</td>\n      <td>cancer</td>\n      <td>Given the title and abstract of a research pap...</td>\n      <td>yes</td>\n      <td>0.196826</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>26432562</td>\n      <td>A Case of Recurrent Ischemic Stroke Involving ...</td>\n      <td>CASE REPORT: A 58-year-old man presenting with...</td>\n      <td>non_cancer</td>\n      <td>Given the title and abstract of a research pap...</td>\n      <td>yes</td>\n      <td>0.803174</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>30937513</td>\n      <td>[Bronchoalveolar lavage in hairy cell leukemia...</td>\n      <td>We report a 78-year-old male patient suffering...</td>\n      <td>cancer</td>\n      <td>Given the title and abstract of a research pap...</td>\n      <td>yes</td>\n      <td>0.735218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def evaluate(y_true, y_pred):\n    labels = [\"yes\", \"no\"]\n    mapping = {label: idx for idx, label in enumerate(labels)}\n    \n    def map_func(x):\n        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n    \n    y_true_mapped = np.vectorize(map_func)(y_true)\n    y_pred_mapped = np.vectorize(map_func)(y_pred)\n    \n    # Calculate accuracy\n    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n    print(f'Accuracy: {accuracy:.3f}')\n    \n    # Generate accuracy report\n    unique_labels = set(y_true_mapped)  # Get unique labels\n    \n    for label in unique_labels:\n        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n        label_y_true = [y_true_mapped[i] for i in label_indices]\n        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n        \n    # Generate classification report\n    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n    print('\\nClassification Report:')\n    print(class_report)\n    \n    # Generate confusion matrix\n    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n    print('\\nConfusion Matrix:')\n    print(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:26:21.180411Z","iopub.execute_input":"2025-05-04T20:26:21.180740Z","iopub.status.idle":"2025-05-04T20:26:21.190245Z","shell.execute_reply.started":"2025-05-04T20:26:21.180718Z","shell.execute_reply":"2025-05-04T20:26:21.189318Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"evaluate(y_val, y_val_pred_df[\"predicted_label\"])","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:26:52.867343Z","iopub.execute_input":"2025-05-04T20:26:52.868233Z","iopub.status.idle":"2025-05-04T20:26:52.889765Z","shell.execute_reply.started":"2025-05-04T20:26:52.868189Z","shell.execute_reply":"2025-05-04T20:26:52.888977Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy: 0.525\nAccuracy for label yes: 1.000\nAccuracy for label no: 0.000\n\nClassification Report:\n              precision    recall  f1-score   support\n\n         yes       0.53      1.00      0.69       105\n          no       0.00      0.00      0.00        95\n\n    accuracy                           0.53       200\n   macro avg       0.26      0.50      0.34       200\nweighted avg       0.28      0.53      0.36       200\n\n\nConfusion Matrix:\n[[105   0]\n [ 95   0]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Finetuning the model","metadata":{}},{"cell_type":"code","source":"import bitsandbytes as bnb\n\ndef find_all_linear_names(model):\n    cls = bnb.nn.Linear4bit\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names:  # needed for 16 bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:28:11.299367Z","iopub.execute_input":"2025-05-04T20:28:11.300091Z","iopub.status.idle":"2025-05-04T20:28:11.305998Z","shell.execute_reply.started":"2025-05-04T20:28:11.300063Z","shell.execute_reply":"2025-05-04T20:28:11.304982Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"modules = find_all_linear_names(model)\nmodules","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:28:12.228319Z","iopub.execute_input":"2025-05-04T20:28:12.228673Z","iopub.status.idle":"2025-05-04T20:28:12.236517Z","shell.execute_reply.started":"2025-05-04T20:28:12.228648Z","shell.execute_reply":"2025-05-04T20:28:12.235619Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['k_proj', 'o_proj', 'v_proj', 'up_proj', 'gate_proj', 'q_proj', 'down_proj']"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## Setting up the model","metadata":{}},{"cell_type":"code","source":"output_dir=\"fine-tuned-model\"\n\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=modules,\n)\n\ntraining_arguments = SFTConfig(\n    output_dir=output_dir,                    # directory to save and repository id\n    num_train_epochs=1,                       # number of training epochs\n    per_device_train_batch_size=1,            # batch size per device during training\n    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n    optim=\"paged_adamw_32bit\",\n    logging_steps=1,                         \n    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n    weight_decay=0.001,\n    fp16=True,\n    bf16=False,\n    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n    max_steps=-1,\n    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n    group_by_length=False,\n    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n    report_to=\"wandb\",                  # report metrics to w&b\n    eval_strategy=\"steps\",              # save checkpoint every epoch\n    eval_steps = 0.2,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    packing=False,\n    dataset_kwargs={\n    \"add_special_tokens\": False,\n    \"append_concat_token\": False,\n    }\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=training_arguments,\n    train_dataset=train_data,\n    eval_dataset=eval_data,\n    peft_config=peft_config,\n    processing_class=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:28:17.574522Z","iopub.execute_input":"2025-05-04T20:28:17.574845Z","iopub.status.idle":"2025-05-04T20:28:19.649595Z","shell.execute_reply.started":"2025-05-04T20:28:17.574822Z","shell.execute_reply":"2025-05-04T20:28:19.648733Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML:   0%|          | 0/600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f59eb01cc3e45329b80cb6db6d4163a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to train dataset:   0%|          | 0/600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"871327996bbc4261ab8b4585fa8072b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f8d5dd152fc4cdca7045130b82b9e5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset:   0%|          | 0/600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f51d0f82a5a54e96bf3055f73965511d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Converting eval dataset to ChatML:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa39d73edc334295a9cc46205a334e46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Adding EOS to eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ec7cf91a780470c8dd3b112c22462a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc95a79db9f6423b82ce97734a9249d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating eval dataset:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9e3140e9c94c04810d15320032daa6"}},"metadata":{}},{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"markdown","source":"- Restricting to only 1 epoch, given the time constraint","metadata":{}},{"cell_type":"code","source":"# Train model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:29:08.821856Z","iopub.execute_input":"2025-05-04T20:29:08.822256Z","iopub.status.idle":"2025-05-04T20:39:35.898727Z","shell.execute_reply.started":"2025-05-04T20:29:08.822231Z","shell.execute_reply":"2025-05-04T20:39:35.897936Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [75/75 10:21, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>15</td>\n      <td>2.065300</td>\n      <td>1.917533</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.821100</td>\n      <td>1.902500</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.763400</td>\n      <td>1.886745</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.669800</td>\n      <td>1.886993</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.871000</td>\n      <td>1.886850</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=75, training_loss=1.8784265120824177, metrics={'train_runtime': 626.7109, 'train_samples_per_second': 0.957, 'train_steps_per_second': 0.12, 'total_flos': 1296270023393280.0, 'train_loss': 1.8784265120824177})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"wandb.finish()\nmodel.config.use_cache = True","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:39:42.344404Z","iopub.execute_input":"2025-05-04T20:39:42.344990Z","iopub.status.idle":"2025-05-04T20:39:48.306639Z","shell.execute_reply.started":"2025-05-04T20:39:42.344959Z","shell.execute_reply":"2025-05-04T20:39:48.305974Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▁▁▁</td></tr><tr><td>eval/mean_token_accuracy</td><td>▁▆▇█▇</td></tr><tr><td>eval/num_tokens</td><td>▁▃▅▆█</td></tr><tr><td>eval/runtime</td><td>▁▇█▇█</td></tr><tr><td>eval/samples_per_second</td><td>█▂▁▂▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▄▃▂▂▄▃█▃▃▃▂▂▁▃▃▂▃▁▂▁▁▂▂▂▁▃▂▂▃▂▂▂▃▂▂▁▂▂▃▃</td></tr><tr><td>train/learning_rate</td><td>▁▃███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▄▅▅▂▄▂▄▄▂▄▃▃▅▄▂▃▃▃▃▂▃▁▄▂▃▂▅▃▆▄▃▃▄▂▂▃▂▃</td></tr><tr><td>train/mean_token_accuracy</td><td>▁▂▄▃▃▄▃▆▄▅▇▄▅▅▃▄▆▆▄▅▅▆▅█▇▆▅▆▄▅▃▆▆▇█▅▆▆▆▆</td></tr><tr><td>train/num_tokens</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.88685</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.5926</td></tr><tr><td>eval/num_tokens</td><td>212176.0</td></tr><tr><td>eval/runtime</td><td>44.0854</td></tr><tr><td>eval/samples_per_second</td><td>4.537</td></tr><tr><td>eval/steps_per_second</td><td>0.567</td></tr><tr><td>total_flos</td><td>1296270023393280.0</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>75</td></tr><tr><td>train/grad_norm</td><td>0.20886</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.871</td></tr><tr><td>train/mean_token_accuracy</td><td>0.61818</td></tr><tr><td>train/num_tokens</td><td>212176.0</td></tr><tr><td>train_loss</td><td>1.87843</td></tr><tr><td>train_runtime</td><td>626.7109</td></tr><tr><td>train_samples_per_second</td><td>0.957</td></tr><tr><td>train_steps_per_second</td><td>0.12</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">old-transport-8</strong> at: <a href='https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera/runs/kmbmd8aa' target=\"_blank\">https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera/runs/kmbmd8aa</a><br/> View project at: <a href='https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera' target=\"_blank\">https://wandb.ai/mohitlakshya/Fine-tuning%20for%20velsera</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250504_201146-kmbmd8aa/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"## Saving the model and tokenizer","metadata":{}},{"cell_type":"code","source":"# Save trained model and tokenizer\ntrainer.save_model(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:40:05.740197Z","iopub.execute_input":"2025-05-04T20:40:05.740982Z","iopub.status.idle":"2025-05-04T20:40:06.501338Z","shell.execute_reply.started":"2025-05-04T20:40:05.740955Z","shell.execute_reply":"2025-05-04T20:40:06.500275Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"('fine-tuned-model/tokenizer_config.json',\n 'fine-tuned-model/special_tokens_map.json',\n 'fine-tuned-model/tokenizer.json')"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"## Testing model after fine-tuning ","metadata":{}},{"cell_type":"code","source":"y_val_pred_df = predict(x_val, model, tokenizer)\nevaluate(y_val, y_val_pred_df[\"predicted_label\"])","metadata":{"execution":{"iopub.status.busy":"2025-05-04T20:40:53.153969Z","iopub.execute_input":"2025-05-04T20:40:53.154745Z","iopub.status.idle":"2025-05-04T20:41:47.873840Z","shell.execute_reply.started":"2025-05-04T20:40:53.154718Z","shell.execute_reply":"2025-05-04T20:41:47.872964Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 200/200 [00:54<00:00,  3.66it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.930\nAccuracy for label yes: 0.886\nAccuracy for label no: 0.979\n\nClassification Report:\n              precision    recall  f1-score   support\n\n         yes       0.98      0.89      0.93       105\n          no       0.89      0.98      0.93        95\n\n    accuracy                           0.93       200\n   macro avg       0.93      0.93      0.93       200\nweighted avg       0.93      0.93      0.93       200\n\n\nConfusion Matrix:\n[[93 12]\n [ 2 93]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"x_test[\"text\"] = [generate_test_prompt(title=t, abstract=a) for t, a in zip(x_test[\"title\"], x_test[\"abstract\"])]\n\ny_preds_test = predict(x_test, model, tokenizer)\nevaluate(y_test, y_preds_test[\"predicted_label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T20:42:02.571145Z","iopub.execute_input":"2025-05-04T20:42:02.571488Z","iopub.status.idle":"2025-05-04T20:42:55.581327Z","shell.execute_reply.started":"2025-05-04T20:42:02.571464Z","shell.execute_reply":"2025-05-04T20:42:55.580425Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 200/200 [00:52<00:00,  3.77it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.950\nAccuracy for label yes: 0.924\nAccuracy for label no: 0.979\n\nClassification Report:\n              precision    recall  f1-score   support\n\n         yes       0.98      0.92      0.95       105\n          no       0.92      0.98      0.95        95\n\n    accuracy                           0.95       200\n   macro avg       0.95      0.95      0.95       200\nweighted avg       0.95      0.95      0.95       200\n\n\nConfusion Matrix:\n[[97  8]\n [ 2 93]]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Conclusion\n\n- The accuracy improved after finetuning. Before finetuning overall accuracy was around 55%, after finetuning the accuracy jumped to 95%\n- The accuracy can further be improved, by using a bigger model or may be increasing the number of epochs. These can be further explored but in interest of time and resources, will park it for later.","metadata":{}}]}